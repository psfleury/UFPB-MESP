# -*- coding: utf-8 -*-
"""Avaliacao_de_Modelos_vf3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hwPc0_3PqPym1JwYE8bjGkO8z2Nqct7U
"""

from google.colab import drive

# Montar o Google Drive
drive.mount('/content/drive')

# Script de consulta da tabela consolidada com armazenamento em dataframe do pandas

import sqlite3
import pandas as pd

# Conectar ao banco de dados SQLite
conn = sqlite3.connect('/content/drive/MyDrive/MESP_Previdencia/mesp_previdencia.db')

# Criar um objeto cursor para executar comandos SQL
cursor = conn.cursor()

# Exemplo de consulta SELECT
consulta = """SELECT * from tabela_pretreinamento;
"""

dados_final = pd.read_sql_query(consulta, conn)

# Fechar a conexão
conn.close()

dados_final.sample(5)

# Importar as bibliotecas necessárias à análise. Em suma: pandas, numpy, matplotlib, nltk, sklearn (diversos) e random
import numpy as np
import pandas as pd
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder
from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm, tree, neighbors
from sklearn.ensemble import RandomForestClassifier
from sklearn.compose import ColumnTransformer
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from random import seed
import matplotlib.pyplot as plt
from sklearn.neural_network import MLPClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.ensemble import ExtraTreesClassifier
from sklearn.ensemble import BaggingClassifier

# Transformar variáveis categóricas em tipo "category"
dados_final['nr_proc'] = dados_final['nr_proc'].astype("category")
dados_final['jurisdicionado'] = dados_final['jurisdicionado'].astype("category")
dados_final['ano'] = dados_final['ano'].astype("category")
dados_final['orgao'] = dados_final['orgao'].astype("category")
dados_final['carreira'] = dados_final['carreira'].astype("category")
dados_final['cargo'] = dados_final['cargo'].astype("category")
dados_final['flag_aposesp'] = dados_final['flag_aposesp'].astype("category")
dados_final['meio_publi'] = dados_final['meio_publi'].astype("category")
dados_final['regra_apos'] = dados_final['regra_apos'].astype("category")
dados_final['qtd_vinculos'] = dados_final['qtd_vinculos'].astype("category")
dados_final['qtd_vinculos_pub'] = dados_final['qtd_vinculos_pub'].astype("category")
dados_final['qtd_vinculos_priv'] = dados_final['qtd_vinculos_priv'].astype("category")
dados_final['qtd_vinculos_mesmo_cargo'] = dados_final['qtd_vinculos_mesmo_cargo'].astype("category")
dados_final['qtd_vinculos_mesma_carreira'] = dados_final['qtd_vinculos_mesma_carreira'].astype("category")
dados_final['p_vencimento'] = dados_final['p_vencimento'].astype("category")
dados_final['p_ats'] = dados_final['p_ats'].astype("category")
dados_final['p_proventos'] = dados_final['p_proventos'].astype("category")
dados_final['p_gratificacao'] = dados_final['p_gratificacao'].astype("category")
dados_final['p_vantpessoal'] = dados_final['p_vantpessoal'].astype("category")
dados_final['p_insalubridade'] = dados_final['p_insalubridade'].astype("category")
dados_final['p_adcqualificacao'] = dados_final['p_adcqualificacao'].astype("category")
dados_final['p_representacao'] = dados_final['p_representacao'].astype("category")
dados_final['p_antecipacao'] = dados_final['p_antecipacao'].astype("category")
dados_final['p_indenizatorio'] = dados_final['p_indenizatorio'].astype("category")
dados_final['ind_sm'] = dados_final['ind_sm'].astype("category")

global cons_transformed_df, cons_tabela_5, cons_tabela_10, cons_tabela_11, cons_tabela_12
cons_transformed_df = pd.DataFrame()
cons_tabela_5 = pd.DataFrame()
cons_tabela_10 = pd.DataFrame()
cons_tabela_11 = pd.DataFrame()
cons_tabela_12 = pd.DataFrame()

for rnd_ind in range(0, 150):
    # Separar dataset em bases de treino (train) e teste (valid)
    # mantendo proporção dos labels (estratify) e com uma seed aleatoriamente escolhida
    features = dados_final[['nr_proc', 'jurisdicionado', 'ano', 'orgao', 'carreira', 'cargo', 'flag_aposesp', 'meio_publi', 'regra_apos', 'qtd_vinculos', 'qtd_vinculos_pub', 'qtd_vinculos_priv', 'qtd_vinculos_mesmo_cargo', 'qtd_vinculos_mesma_carreira', 'p_vencimento', 'p_ats', 'p_proventos', 'p_gratificacao', 'p_vantpessoal', 'p_insalubridade', 'p_adcqualificacao', 'p_representacao', 'p_antecipacao', 'p_indenizatorio', 'ind_sm']]
    label = dados_final['rotulo']
    x_train, x_valid, y_train, y_valid = model_selection.train_test_split(features, label, random_state=rnd_ind, stratify=label)

    # Parametrizando o pré-processamento das features

    categorical_features = ['nr_proc', 'jurisdicionado', 'ano', 'orgao', 'carreira', 'cargo', 'flag_aposesp', 'meio_publi', 'regra_apos', 'qtd_vinculos', 'qtd_vinculos_pub', 'qtd_vinculos_priv', 'qtd_vinculos_mesmo_cargo', 'qtd_vinculos_mesma_carreira', 'p_vencimento', 'p_ats', 'p_proventos', 'p_gratificacao', 'p_vantpessoal', 'p_insalubridade', 'p_adcqualificacao', 'p_representacao', 'p_antecipacao', 'p_indenizatorio', 'ind_sm']
    categorical_transformer = OneHotEncoder(handle_unknown="ignore")

    preprocessor = ColumnTransformer(
        transformers=[
            ("categorical columns", categorical_transformer, categorical_features)
        ]
    )

    global global_df
    global_df = pd.DataFrame({'nr_proc': x_valid['nr_proc'], 'y_valid': y_valid})

    # Criar um DataFrame global vazio
    confusion_matrix_df = pd.DataFrame(columns=['Model', 'TN', 'FP', 'FN', 'TP'])

    # Função para adicionar uma matriz de confusão ao DataFrame global
    def add_confusion_matrix(model_name, confusion_matrix):
        global confusion_matrix_df

        # Extrair os valores da matriz de confusão
        TN, FP, FN, TP = confusion_matrix.ravel()

        # Criar um DataFrame temporário para a matriz de confusão atual
        df = pd.DataFrame({
            'Model': [model_name],
            'TN': [TN],
            'FP': [FP],
            'FN': [FN],
            'TP': [TP]
        })

        confusion_matrix_df = pd.concat([confusion_matrix_df, df], ignore_index=True)

    # Cria função que parametriza o treinamento de um modelo definido como input, faz suas predições, cria a matriz de confusão e preenche um dataframe global de informações importantes para o modelo rodado

    def train_model(classifier, feature_vector_train, label, feature_vector_valid, label_valid, titulo_mapa, is_neural_net=False):
      clf = Pipeline(steps=[("preprocessor", preprocessor), ("classifier", classifier)])
      clf.fit(feature_vector_train, label)
      pred_test = clf.predict(feature_vector_valid)
      conf_mat = confusion_matrix(label_valid, pred_test)
      add_confusion_matrix(titulo_mapa, conf_mat)
      global_df[titulo_mapa] = pred_test


    import numpy as np
    import pandas as pd
    import seaborn as sns
    from sklearn.model_selection import train_test_split
    from sklearn.pipeline import Pipeline
    from sklearn.preprocessing import OneHotEncoder
    from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm, tree, neighbors
    from sklearn.ensemble import RandomForestClassifier
    from sklearn.compose import ColumnTransformer
    from sklearn.metrics import confusion_matrix
    from sklearn.metrics import classification_report
    from random import seed
    import matplotlib.pyplot as plt
    from sklearn.neural_network import MLPClassifier
    from sklearn.ensemble import AdaBoostClassifier
    from sklearn.ensemble import GradientBoostingClassifier
    from sklearn.ensemble import ExtraTreesClassifier
    from sklearn.ensemble import BaggingClassifier

    ### Função das previsões do Comitê Classificador:
    classificador={
                   "Logistic Regression":linear_model.LogisticRegression(max_iter = 50000),
                   "Naive Bayes": naive_bayes.MultinomialNB(),
                   "KNN": neighbors.KNeighborsClassifier(n_neighbors=5, algorithm='auto'),
                   "SVM": svm.SVC(),
                   "Decision Tree": tree.DecisionTreeClassifier(random_state=rnd_ind),
                   "Random Forest":RandomForestClassifier(random_state=rnd_ind),
                   "Bagging":BaggingClassifier(random_state=rnd_ind),
                   "MLPClassifier": MLPClassifier(hidden_layer_sizes=(15,15,15,15), activation='relu', solver='adam', alpha=0.0001,
                                                 batch_size='auto', learning_rate='constant', learning_rate_init=0.001,
                                                 power_t=0.5, max_iter=200000, shuffle=True, random_state=rnd_ind, tol=0.0001,
                                                 verbose=False, warm_start=True, momentum=0.9, nesterovs_momentum=True, early_stopping=False,
                                                 validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=100, max_fun=15000),
                   "ADA": AdaBoostClassifier(n_estimators=100, algorithm="SAMME",),
                   "Gradient Boost": GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=1, random_state=rnd_ind),
                   "Extratree"     : ExtraTreesClassifier(n_estimators=10, max_depth=None, min_samples_split=2, random_state=rnd_ind)
                }
    for i , (clf_name, classifier) in enumerate (classificador.items()):
        train_model(classifier, x_train, y_train, x_valid, y_valid, clf_name)

    global_df_adjust = global_df.copy()
    colunas_nao_binarias = ['nr_proc', 'y_valid']
    colunas_binarias = [coluna for coluna in global_df_adjust.columns if coluna not in colunas_nao_binarias]
    global_df_adjust[colunas_binarias] = global_df_adjust[colunas_binarias].replace(0, -1)

    global_df_adjust['Soma_Modelos']=global_df_adjust[colunas_binarias].sum(axis=1)
    colunas_nao_binarias = ['nr_proc', 'y_valid', 'Soma_Modelos']
    colunas_binarias = [coluna for coluna in global_df_adjust.columns if coluna not in colunas_nao_binarias]
    global_df_adjust[colunas_binarias] = global_df_adjust[colunas_binarias].replace(-1, 0)
    global_df_adjust['Modulo_Soma'] = global_df_adjust['Soma_Modelos'].abs()
    global_df_adjust['Class_Coletiva'] = global_df_adjust.Soma_Modelos.apply(lambda x: 1 if x >=0 else 0)


    import pandas as pd
    from sklearn.metrics import classification_report, confusion_matrix
    import numpy as np

    # Crie um DataFrame vazio para armazenar os resultados
    df_consolidado = pd.DataFrame()

    # Mapeamento de nomes dos subconjuntos de dados
    comite_names = {
        11: "Subconjunto Consenso 11",
        9: "Subconjunto Consenso 10",
        7: "Subconjunto Consenso 9",
        5: "Subconjunto Consenso 8",
        3: "Subconjunto Consenso 7",
        1: "Subconjunto Consenso 6"
    }

    # Nome das colunas dos modelos preditivos
    model_columns = [
        'Logistic Regression', 'Naive Bayes', 'KNN', 'SVM',
        'Decision Tree', 'Random Forest', 'Bagging',
        'MLPClassifier', 'ADA', 'Gradient Boost', 'Extratree'
    ]

    # Iterar sobre os possíveis valores de módulo soma (modulo_soma = 11 é consenso unânime, =9 é consenso de 10, =7 consenso de 9, =5 consenso de 8, =3 consenso de 7, =1 consenso de 6)
    for i in range(11, 0, -2):
        # Selecionar registros que compõem o subconjunto
        transfor_n = global_df_adjust.loc[global_df_adjust['Modulo_Soma'] == i].copy()

        # Aplicar a transformação nos valores de Soma_Modelos
        transfor_n_report = transfor_n['Soma_Modelos'].apply(lambda x: 1 if x >= 0 else 0)

        # Gerar o relatório de classificação para a escolha coletiva do subconjunto de dados
        dicio = classification_report(transfor_n['y_valid'].values, transfor_n_report.values, digits=6, output_dict=True)
        dicio.pop("accuracy")
        dicio.pop("macro avg")
        dicio.pop("weighted avg")

        # Gerar a matriz de confusão para a escolha coletiva
        conf_mat_cs = confusion_matrix(transfor_n['y_valid'], transfor_n_report)
        comite_name = comite_names.get(i)
        add_confusion_matrix(comite_name, conf_mat_cs)

        # Transformar o dicionário resultante em DataFrame e adicionar uma coluna para a iteração
        df_temp = pd.DataFrame(dicio).T
        df_temp["Modelo"] = comite_name
        df_temp["Classe"] = df_temp.index

        # Concatenar o DataFrame temporário ao DataFrame consolidado
        df_consolidado = pd.concat([df_consolidado, df_temp])

        # Calcular a matriz de confusão para cada modelo individual no subconjunto de dados
        for model in model_columns:
            y_pred = transfor_n[model]
            y_true = transfor_n['y_valid']
            conf_matrix = confusion_matrix(y_true, y_pred)
            add_confusion_matrix(f"{comite_name} - {model}", conf_matrix)

            # Gerar o relatório de classificação para cada modelo individual
            dicio_model = classification_report(y_true, y_pred, digits=6, output_dict=True)
            dicio_model.pop("accuracy")
            dicio_model.pop("macro avg")
            dicio_model.pop("weighted avg")

            # Transformar o dicionário resultante em DataFrame e adicionar uma coluna para a iteração
            df_temp_model = pd.DataFrame(dicio_model).T
            df_temp_model["Modelo"] = f"{comite_name} - {model}"
            df_temp_model["Classe"] = df_temp_model.index

            # Concatenar o DataFrame temporário ao DataFrame consolidado
            df_consolidado = pd.concat([df_consolidado, df_temp_model])

    import pandas as pd

    rl = classification_report(y_valid, global_df['Logistic Regression'], digits=6, output_dict=True)
    nb = classification_report(y_valid, global_df['Naive Bayes'], digits=6, output_dict=True)
    knn = classification_report(y_valid, global_df['KNN'], digits=6, output_dict=True)
    svm = classification_report(y_valid, global_df['SVM'], digits=6, output_dict=True)
    ad = classification_report(y_valid, global_df['Decision Tree'], digits=6, output_dict=True)
    fr = classification_report(y_valid, global_df['Random Forest'], digits=6, output_dict=True)
    bag = classification_report(y_valid, global_df['Bagging'], digits=6, output_dict=True)
    mlpc = classification_report(y_valid, global_df['MLPClassifier'], digits=6, output_dict=True)
    ada = classification_report(y_valid, global_df['ADA'], digits=6, output_dict=True)
    gboo = classification_report(y_valid, global_df['Gradient Boost'], digits=6, output_dict=True)
    xt = classification_report(y_valid, global_df['Extratree'], digits=6, output_dict=True)

    # Consolidar os dicionários em um único dicionário de dicionários
    reports_dict = {'Logistic Regression': rl,
                    'Naive Bayes': nb,
                    'KNN': knn,
                    'SVM': svm,
                    'Decision Tree': ad,
                    'Random Forest': fr,
                    'Bagging': bag,
                    'MLPClassifier': mlpc,
                    'ADA': ada,
                    'Gradient Boost': gboo,
                    'Extratree': xt}

    # Lista para armazenar os dados consolidados
    consolidated_data = []

    # Iterar sobre os dicionários de classification_report de cada modelo
    for model_name, report_dict in reports_dict.items():
        # Iterar sobre as classes de cada modelo
        for class_name, metrics_dict in report_dict.items():
            # Verificar se metrics_dict é um dicionário válido
            if isinstance(metrics_dict, dict):
                # Adicionar um novo dicionário com os indicadores, incluindo o nome do modelo e o nome da classe
                consolidated_data.append({'Modelo': model_name, 'Classe': class_name, **metrics_dict})


    # Criar DataFrame a partir dos dados consolidados
    consolidated_df = pd.DataFrame(consolidated_data)

    consolidated_df = consolidated_df.loc[consolidated_df['Classe'].isin(['0', '1'])]

    df_final = pd.concat([consolidated_df, df_consolidado], ignore_index=True)

    import pandas as pd

    # Transformar o DataFrame usando pivot_table
    transformed_df = df_final.pivot_table(index='Modelo', columns='Classe', values=['precision', 'recall', 'f1-score', 'support'])

    # Renomear as colunas para refletir as classes
    transformed_df.columns = [f'{indicator}_{class_}' for indicator, class_ in transformed_df.columns]

    # Resetar o índice para garantir que 'Modelo' seja uma coluna
    transformed_df = transformed_df.reset_index()

    # Mesclar os DataFrames usando os campos de cruzamento diferentes
    transformed_df = pd.merge(transformed_df, confusion_matrix_df, left_on='Modelo', right_on='Model')

    ordem_colunas = ['Modelo','TN', 'FP', 'FN', 'TP', 'f1-score_0', 'f1-score_1', 'precision_0', 'precision_1', 'recall_0', 'recall_1', 'support_0', 'support_1']

    transformed_df = transformed_df[ordem_colunas]

    test_base_size = y_valid.shape[0]
    transformed_df["Beneficio"] = transformed_df["TN"]
    transformed_df["Custo"] = transformed_df["FN"]
    transformed_df["Beneficio/Custo"] = transformed_df["Beneficio"] / transformed_df["Custo"]
    coluna_para_ordenar = 'Beneficio/Custo'
    transformed_df = transformed_df.sort_values(by=coluna_para_ordenar, ascending=False)

    transformed_df['Accuracy'] = (transformed_df['TN'] + transformed_df['TP']) / (transformed_df['support_0'] + transformed_df['support_1'])
    transformed_df = transformed_df.drop_duplicates()

    transf_df_iteracao = transformed_df.copy()

    # Adiciona uma coluna 'Iteracao' para indicar o número da iteração
    transf_df_iteracao['Iteracao'] = rnd_ind

    # Concatenar a tabela_5 ao cons_tabela_5
    cons_transformed_df = pd.concat([cons_transformed_df, transf_df_iteracao], ignore_index=True)



# Combinar os dataframes (acrescentar as linhas do novo dataframe ao existente)
cons_transformed_df = pd.concat([cons_transformed_df, df_novo], ignore_index=True)

# Exibir as primeiras linhas do dataframe combinado
cons_transformed_df.shape

colunas_para_remover = [coluna for coluna in cons_transformed_df.columns if any(substring in coluna for substring in ["f1-score", "precision", "recall", "Accuracy", "support"])]

cons_transformed_df = cons_transformed_df.drop(columns=colunas_para_remover)

colunas_para_remover = ['Beneficio', 'Custo']

cons_transformed_df = cons_transformed_df.drop(columns=colunas_para_remover)

import pandas as pd

cons_transformed_df_coletivas = cons_transformed_df[cons_transformed_df['Modelo'].str.contains('Consenso') & ~cons_transformed_df['Modelo'].str.contains('-')]

# Filtrar as linhas onde "Modelo" contém '6', '7' ou '8'
filtered_678df = cons_transformed_df_coletivas[cons_transformed_df_coletivas['Modelo'].str.contains('6|7|8')]

grouped_678df = filtered_678df.groupby(['Iteracao']).agg({
    'TN': 'sum',
    'FP': 'sum',
    'FN': 'sum',
    'TP': 'sum'
}).reset_index()

# Adicionar uma coluna "Modelo" indicando o agrupamento
grouped_678df['Modelo'] = 'Subconjunto Consenso 8 ou menos modelos'
grouped_678df['Beneficio/Custo'] = grouped_678df['TN'] / grouped_678df['FN']

# Filtrar as linhas onde "Modelo" contém '9', '10' ou '11'
filtered_91011df = cons_transformed_df_coletivas[cons_transformed_df_coletivas['Modelo'].str.contains('9|10|11')]

# Agrupar por "Iteracao" e somar as colunas desejadas, mantendo o "Modelo"
grouped_91011df = filtered_91011df.groupby(['Iteracao']).agg({
    'TN': 'sum',
    'FP': 'sum',
    'FN': 'sum',
    'TP': 'sum'
}).reset_index()

# Adicionar uma coluna "Modelo" indicando o agrupamento
grouped_91011df['Modelo'] = 'Subconjunto Consenso 9 ou mais modelos'
grouped_91011df['Beneficio/Custo'] = grouped_91011df['TN'] / grouped_91011df['FN']

# Adicionar as linhas derivadas do agrupamento ao dataframe original
cons_transformed_df_coletivas = pd.concat([cons_transformed_df_coletivas, grouped_678df, grouped_91011df], ignore_index=True)

import pandas as pd
import scipy.stats as stats
import numpy as np

# Supondo que o dataframe se chame cons_transformed_df
# Função para calcular a margem de erro e o intervalo de confiança
def calc_confidence_interval(data, confidence=0.95):
    n = len(data)
    mean = np.mean(data)
    stderr = stats.sem(data)  # Calcula o erro padrão da média
    margin_of_error = stderr * stats.t.ppf((1 + confidence) / 2., n-1)
    margin_of_error_percent = (margin_of_error / mean) * 100 if mean != 0 else np.inf
    return f"{mean:.2f} ± {margin_of_error:.2f} ({margin_of_error_percent:.2f}%)"

# Aplicar a função a cada coluna (exceto "Modelo") para calcular a média e o intervalo de confiança
confidence_intervals = cons_transformed_df_coletivas.groupby('Modelo').agg(lambda x: calc_confidence_interval(x)).reset_index()

colunas_para_remover = ['Iteracao']

ic_escolhacoletiva = confidence_intervals.drop(columns=colunas_para_remover)

ic_escolhacoletiva.head(20)

# Filtrar as linhas onde "Modelo" contém '6', '7' ou '8'
cons_transformed_df_ind = cons_transformed_df[cons_transformed_df['Modelo'].str.contains(' - ')]

filtered_678df = cons_transformed_df_ind[cons_transformed_df_ind['Modelo'].str.contains('6|7|8')]

filtered_678df['Nome_Modelo'] = filtered_678df['Modelo'].str.split(' - ').str[-1]

grouped_678df = filtered_678df.groupby(['Iteracao', 'Nome_Modelo']).agg({
    'TN': 'sum',
    'FP': 'sum',
    'FN': 'sum',
    'TP': 'sum'
}).reset_index()

# Adicionar uma coluna "Modelo" indicando o agrupamento
grouped_678df["Modelo"] = "Subconjunto Consenso 8 ou menos" + " - " + grouped_678df["Nome_Modelo"]
grouped_678df['Beneficio/Custo'] = grouped_678df['TN'] / grouped_678df['FN']

# Adicionar as linhas derivadas do agrupamento ao dataframe original
cons_transformed_df_ind = pd.concat([cons_transformed_df_ind, grouped_678df], ignore_index=True)

import pandas as pd
import scipy.stats as stats
import numpy as np

cons_transformed_df_ind = cons_transformed_df_ind.drop(columns=["Nome_Modelo"])

# Supondo que o dataframe se chame cons_transformed_df
# Função para calcular a margem de erro e o intervalo de confiança
def calc_confidence_interval(data, confidence=0.95):
    n = len(data)
    mean = np.mean(data)
    stderr = stats.sem(data)  # Calcula o erro padrão da média
    margin_of_error = stderr * stats.t.ppf((1 + confidence) / 2., n-1)
    margin_of_error_percent = (margin_of_error / mean) * 100 if mean != 0 else np.inf
    return f"{mean:.2f} ± {margin_of_error:.2f} ({margin_of_error_percent:.2f}%)"

# Aplicar a função a cada coluna (exceto "Modelo") para calcular a média e o intervalo de confiança
confidence_intervals_ind = cons_transformed_df_ind.groupby('Modelo').agg(lambda x: calc_confidence_interval(x)).reset_index()

colunas_para_remover = ['Iteracao']

ic_escolhaindividual = confidence_intervals_ind.drop(columns=colunas_para_remover)
ic_escolhaindividual.head(20)
